"""
Adversarial ML Lab - Source Package
===================================
Interactive demonstrations of adversarial ML attacks and defenses.

This package provides:
- Attack simulations (prompt injection, context tampering, inference evasion)
- Defense mechanisms (context filters, isolation, uncertainty scoring)
- Educational visualizations

SECURITY NOTE: This code is for educational demonstration purposes only.
Do not use these attack techniques against production systems without authorization.
"""

__version__ = "0.1.0"
__author__ = "Mayur"
